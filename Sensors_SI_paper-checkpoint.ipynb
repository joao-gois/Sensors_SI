{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilmtk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import os, ast\n",
    "from sys import argv\n",
    "from time import time\n",
    "import nilmtk\n",
    "import nilmtk_contrib\n",
    "from nilmtk.api import API\n",
    "from nilmtk.disaggregate import Mean, FHMMExact, CO, Hart85\n",
    "from nilmtk_contrib.disaggregate import AFHMM, AFHMM_SAC, DSC, DAE, Seq2Point, Seq2Seq, RNN, WindowGRU\n",
    "nilmtk.Appliance.allow_synonyms=False\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from scipy import stats as scp_stats\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#To import REFIT dataset\n",
    "dataset = nilmtk.DataSet('REFIT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment period\n",
    "dataset.set_window(\"2014-06-21\", \"2015-06-20\")\n",
    "\n",
    "#To select the washing machine consumption data for the experiment period (1 year)\n",
    "#choose house\n",
    "house = 2\n",
    "dataset_wm=next(dataset.buildings[house].elec[\"washing machine\"].load())['power']\n",
    "\n",
    "#To access which individual appliances were monitored in house 20 for the experiment period\n",
    "dataset.buildings[house].elec\n",
    "\n",
    "#To acess the washing machine activations in house 20 for the experiment period\n",
    "dataset.buildings[house].elec[\"washing machine\"].get_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dividing the consumption data in the experimento period into training (2/3)  and testing (1/3)\n",
    "\n",
    "#choose appliance\n",
    "appliance= \"washing machine\" \n",
    "\n",
    "dataset_wm=next(dataset.buildings[house].elec[appliance].load())['power']\n",
    "\n",
    "X = dataset_wm.values\n",
    "tscv = TimeSeriesSplit(n_splits = 2)\n",
    "\n",
    "train_index_num = []\n",
    "test_index_num = [] \n",
    "for train_index, test_index in tscv.split(X):\n",
    "\n",
    "    X_train, X_test = X[train_index, :], X[test_index, :]\n",
    "    train_index_num.append(train_index)\n",
    "    test_index_num.append(test_index)\n",
    "    \n",
    "train_inic = dataset_wm[0: train_index_num[1][-1]].index[0].strftime('%Y-%m-%d')\n",
    "train_fim = dataset_wm[0: train_index_num[1][-1]].index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "test_inic = dataset_wm[test_index_num[1][0]: test_index_num[1][-1]].index[0].strftime('%Y-%m-%d')\n",
    "test_fim = dataset_wm[test_index_num[1][0]: test_index_num[1][-1]].index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "print('Train start: {}'.format(train_inic))\n",
    "print('Train end: {}'.format(train_fim))\n",
    "print('Test start: {}'.format(test_inic))\n",
    "print('Test end: {}'.format(test_fim))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data is originally sampled at approx. 1/8 Hz. To resample for 1/60 Hz, set sampling_interval = 8  \n",
    "#To resample for 1/300 Hz, set sampling_interval = 40 \n",
    "\n",
    "sampling_interval = 8 \n",
    "load = 'washing machine'\n",
    "\n",
    "#limits for the training and test set defined in the previous cell\n",
    "train_inicio=train_inic\n",
    "train_final=train_fim\n",
    "test_inicio=test_inic\n",
    "test_final= test_fim\n",
    "\n",
    "ep = 200 #number of epochs\n",
    "batch = 1024 #batch size\n",
    "\n",
    "#run the disaggregation experiment\n",
    "experiment = {\n",
    "    'power': { 'mains': ['active'], 'appliance': ['active'] },\n",
    "    'sample_rate': sampling_interval,\n",
    "    'appliances': [load],\n",
    "    'methods': { \n",
    "        \n",
    "        #'RNN': RNN({'n_epochs': ep, 'batch_size': batch})  },\n",
    "        'DAE': DAE({'n_epochs': ep, 'batch_size': batch}) ,    \n",
    "        'Seq2Point': Seq2Point({'n_epochs': ep, 'batch_size': batch})    ,\n",
    "        'Seq2Seq': Seq2Seq({'n_epochs': ep, 'batch_size': batch})     }\n",
    "        #'WindowGRU':WindowGRU({'n_epochs': ep,'batch_size': batch}),\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "            'REFIT': {\n",
    "                'path': 'REFIT.h5'.format(),\n",
    "                'buildings': {\n",
    "                    house: {\n",
    "                        'start_time': train_inicio,\n",
    "                        'end_time': train_final\n",
    "                }\n",
    "                }\n",
    "        }\n",
    "    }\n",
    "},\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'REFIT': {\n",
    "                'path': 'REFIT.h5'.format(),\n",
    "                'buildings': {\n",
    "                     house: {\n",
    "                         'start_time': test_inicio,\n",
    "                         'end_time': test_final\n",
    "                        } \n",
    "                    }\n",
    "            }\n",
    "    },   \n",
    "    'metrics': ['mae']\n",
    "    }\n",
    "} \n",
    "    \n",
    "# Conduct experiment in NILMTK\n",
    "api_results = API(experiment)\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_stats.shapiro(np.log2(seq2point_mw_1_60))\n",
    "#scp_stats.shapiro(seq2point_mw_1_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectors of the disaggregation performances of algorithms for WM, DW, and MW \n",
    "\n",
    "#MAE \n",
    "\n",
    "dae_wm_1_60 = [32.30, 27.01, 46.16, 5.49, 15.58, 30.69, 10.21, 16.69, 5.65, 3.27, 7.74]\n",
    "seq2point_wm_1_60 = [15.62, 19.98, 39.37, 3.07, 11.63, 19.26, 4.85, 10.21, 3.33, 1.32, 4.85]\n",
    "seq2seq_wm_1_60 = [18.94,19.87,42.71,3.97,12.56,21.66,4.90,11.21,3.89,1.40,6.39]\n",
    "\n",
    "dae_wm_1_300 = [20.46,30.74,44.40,6.23,14.68,26.34,7.97,17.21,5.95,3.29,7.17]\n",
    "seq2point_wm_1_300 = [16.55,19.72,41.39,2.96,12.01,18.73,6.80,10.72,3.60,2.21,6.26]\n",
    "seq2seq_wm_1_300 = [19.99,20.05,44.00,3.76,11.09,20.01,6.75,9.63,3.92,2.34,5.20]\n",
    "\n",
    "dae_dw_1_60 = [43.51,28.29,27.23,4.51,18.83,31.11,6.69,62.11,1.27,4.77,6.05]\n",
    "seq2point_dw_1_60 = [53.99,21.26,26.86,3.70,17.93,28.17,5.60,72.66,0.50,4.80,3.94]\n",
    "seq2seq_dw_1_60 = [45.07,24.07,23.20,3.61,16.82,30.21,5.72,66.44,0.72,4.15,4.27]\n",
    "\n",
    "dae_dw_1_300 = [28.34,28.25,27.90,5.10,17.49,33.89,5.61,77.68,0.58,5.21,3.74]\n",
    "seq2point_dw_1_300 = [26.95,20.32,20.41,5.42,12.34,33.20,4.24,77.33,0.92,3.80,3.94]\n",
    "seq2seq_dw_1_300 = [26.41,20.58,22.12,8.32,12.28,31.72,3.68,73.21,0.49,4.58,3.17]\n",
    "\n",
    "dae_mw_1_30 = [3.50,   4.06,   21.27,   4.38,   1.98,   2.15,   1.61,   17.46,   0.60,   2.11,   7.04 ]\n",
    "seq2point_mw_1_30 = [2.86,3.72,16.85,4.21,1.73,1.65,2.83,15.27,0.41,1.91,5.53]\n",
    "seq2seq_mw_1_30 = [3.06,   3.67,   18.28,   4.18,   1.66,   1.65,   1.46,   16.00,   0.48,   2.07,   5.07 ]\n",
    "\n",
    "dae_mw_1_60 = [4.24,4.93,21.82,5.06,2.02,2.61,1.57,15.96,0.63,2.35,5.16]\n",
    "seq2point_mw_1_60 = [2.95,3.89,16.39,3.74,1.89,1.57,2.82,18.56,0.55,2.01,2.07]\n",
    "seq2seq_mw_1_60 = [3.62,3.63,18.05,4.14,1.58,1.61,1.42,17.74,0.53,2.03,3.90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Two-sample Kolmogorov-Smirnov tests to assess if the response sample distributions (of each algorithm) are close \n",
    "#among one another - If that is the case, it indicates that the mean can be a resonable indicator for comparing, in general,\n",
    "#the performance of an algorithm throughout the households\n",
    "\n",
    "#The null hypothesis is that the two distributions are identical, F(x)=G(x) for all x; the alternative is that they \n",
    "#are not identical.\n",
    "#If the KS statistic is small or the p-value is high, then we cannot reject the null hypothesis in favor of the alternative.\n",
    "\n",
    "#For the wm\n",
    "\n",
    "[scp_stats.ks_2samp(dae_wm_1_60, seq2seq_wm_1_60), scp_stats.ks_2samp(dae_wm_1_60, seq2point_wm_1_60), \n",
    " scp_stats.ks_2samp(seq2point_wm_1_60, seq2seq_wm_1_60) ]\n",
    "\n",
    "[scp_stats.ks_2samp(dae_wm_1_300, seq2seq_wm_1_300), scp_stats.ks_2samp(dae_wm_1_300, seq2point_wm_1_300), \n",
    "scp_stats.ks_2samp(seq2point_wm_1_300, seq2seq_wm_1_300) ]\n",
    "\n",
    "#for the dw\n",
    "[scp_stats.ks_2samp(dae_dw_1_60, seq2seq_dw_1_60), scp_stats.ks_2samp(dae_dw_1_60, seq2point_dw_1_60), \n",
    " scp_stats.ks_2samp(seq2point_dw_1_60, seq2seq_dw_1_60) ]\n",
    "\n",
    "[scp_stats.ks_2samp(dae_dw_1_300, seq2seq_dw_1_300), scp_stats.ks_2samp(dae_dw_1_300, seq2point_dw_1_300), \n",
    " scp_stats.ks_2samp(seq2point_dw_1_300, seq2seq_dw_1_300) ]\n",
    "\n",
    "#for the mw\n",
    "[scp_stats.ks_2samp(dae_mw_1_30, seq2seq_mw_1_30), scp_stats.ks_2samp(dae_mw_1_30, seq2point_mw_1_30), \n",
    " scp_stats.ks_2samp(seq2point_mw_1_30, seq2seq_mw_1_30) ]\n",
    "\n",
    "[scp_stats.ks_2samp(dae_mw_1_60, seq2seq_mw_1_60), scp_stats.ks_2samp(dae_mw_1_60, seq2point_mw_1_60), \n",
    " scp_stats.ks_2samp(seq2point_mw_1_60, seq2seq_mw_1_60) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test normality for seq2point performances for 1/300 Hz\n",
    "scp_stats.shapiro(seq2point_mw_1_60)\n",
    "scp_stats.normaltest(seq2point_wm_1_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To obtain the Box-Cox transformation that makes the response sample distribution closer to normal distribution \n",
    "fitted_data, fitted_lambda = scp_stats.boxcox(seq2point_wm_1_300)\n",
    "fitted_lambda\n",
    "  \n",
    "# creating axes to draw plots\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "      \n",
    "# plotting the original response vector sample distributions and also for the respective log-transformations\n",
    "plot1 = sns.distplot(seq2seq_dw_1_60, hist = True, kde = True,\n",
    "            kde_kws = {'shade': False, 'linewidth': 2, 'label': \"KDE\"}, label=\"Hist\", color =\"green\", ax = ax[0])\n",
    "  \n",
    "plot2 = sns.distplot(np.log2(seq2seq_dw_1_60), hist = True, kde = True,\n",
    "            kde_kws = {'shade': False, 'linewidth': 2, 'label': \"KDE\"}, label=\"Hist\", color =\"green\", ax = ax[1])\n",
    "\n",
    "sr = \"1/60\"\n",
    "alg = \"Seq2Seq\"\n",
    "load = \"dishwasher\"\n",
    "\n",
    "plot1.set_xlabel(\"Y, \"+sr+\" Hz\", fontsize = 28)\n",
    "plot1.set_ylabel(\"Probability\", fontsize = 28)\n",
    "plot1.tick_params(axis='x', labelsize=24)\n",
    "plot1.tick_params(axis='y', labelsize=24)\n",
    "\n",
    "\n",
    "plot2.set_xlabel(\"log (Y, \"+sr+\" Hz)\", fontsize = 28)\n",
    "plot2.set_ylabel(\"Probability\", fontsize = 28) \n",
    "plot2.tick_params(axis='x', labelsize=24)\n",
    "plot2.tick_params(axis='y', labelsize=24)\n",
    "\n",
    "\n",
    "plot1.legend(loc = \"upper right\", fontsize = 24)\n",
    "plot2.legend(loc = \"upper right\", fontsize = 24)\n",
    "  \n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(19)\n",
    "fig.suptitle(alg+\" performance for the \"+load+\" at \"+sr+\" Hz\", fontsize  = 28)\n",
    "print(\"Lambda value used for Transformation:\"+ str(fitted_lambda))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the data for backward stepwise selection\n",
    "REFIT_features_data = {'occupancy': [4, 2, 4, 2, 2, 4, 1, 4, 1, 2, 2],\n",
    "                       'dwelling age': ['1919-1944', '1988', '1878', '2005', '1919-1944', '1919-1944', \n",
    "                                        '1945-1964', 'post 2002', '1965-1974', '1965-1974', '1965-1974'], \n",
    "                       'number of appliances': [15, 27, 44, 49, 24, 31, 25, 28, 19, 34, 39],\n",
    "                       'dwelling type': ['semi-detached', 'detached', 'mid-terrace', 'detached', 'detached', \n",
    "                                         'detached', 'detached', 'detached', 'semi-detached', 'detached', 'detached'],\n",
    "                       'size': [3, 3, 4, 4, 3, 3, 3, 4, 3, 3, 3],\n",
    "                       'Y': seq2point_mw_1_60\n",
    "                       \n",
    "        }\n",
    "\n",
    "\n",
    "REFIT_features_data = pd.DataFrame(REFIT_features_data, index=['H2', 'H3', 'H5', 'H6', 'H9', 'H10', 'H11', 'H13', \n",
    "                                                              'H15', 'H18', 'H20'])\n",
    "\n",
    "# features dwelling type and age are categorical, hence are modelled as dummies\n",
    "# for each of them, one of the categories is left out for avoiding redundancy and collinearity\n",
    "#the first category without loss of generality\n",
    "REFIT_features_data = pd.get_dummies(REFIT_features_data, drop_first=True)\n",
    "REFIT_features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log-transformation\n",
    "REFIT_features_data[['logY']]=np.log2(REFIT_features_data[['Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward stepwise selection\n",
    "REFIT_features_data = sm.add_constant(REFIT_features_data)\n",
    "\n",
    "ks = sm.OLS(REFIT_features_data[['logY']], REFIT_features_data[[#'occupancy', \n",
    "                                                                'size', \n",
    "                                                                #'number of appliances', \n",
    "                                                                #'dwelling age_1919-1944', \n",
    "                                                                #'dwelling age_1945-1964',\n",
    "                                                                #'dwelling age_1965-1974', \n",
    "                                                                #'dwelling age_1988', \n",
    "                                                                #'dwelling age_2005', \n",
    "                                                                #'dwelling age_post 2002',\n",
    "                                                                #'dwelling type_mid-terrace', \n",
    "                                                                #'dwelling type_semi-detached', \n",
    "                                                                'const'\n",
    "                                                                ]])\n",
    "\n",
    "\n",
    "ks_res =ks.fit()\n",
    "ks_res.summary(), "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
